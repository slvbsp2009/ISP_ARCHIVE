# MIT License
#
# Deep Joint Demosaicking and Denoising
# Siggraph Asia 2016
# Michael Gharbi, Gaurav Chaurasia, Sylvain Paris, Fredo Durand
# 
# Copyright (c) 2016 Michael Gharbi
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

layer {
  name: "mosaick"
  type: "Input"
  top: "mosaick"
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 128
      dim: 128
    }
  }
}
layer {
  name: "noise_level"
  type: "Input"
  top: "noise_level"
  input_param {
    shape {
      dim: 64
    }
  }
}

# Pack mosaick
layer { 
    bottom: 'mosaick'
    top:  'packed_mosaick' 
    name: 'pack_mosaick' 
    type: 'Convolution'
    param {lr_mult: 0 decay_mult: 0}
    convolution_param {  
        num_output: 4
        kernel_size: 2
        stride:2
        weight_filler {
            type: "constant"
            value: 0
        }
    }
}

layer {
  name: "replicated_noise_level"
  type: "Python"
  bottom: "noise_level"
  bottom: "packed_mosaick"
  top: "replicated_noise_level"
  python_param {
    module: "demosaicnet.layers"
    layer: "ReplicateLikeLayer"
  }
}
    
layer {
    name: 'packed_input'
    bottom: "packed_mosaick"
    bottom: "replicated_noise_level"
    
    top: 'packed_input'
    type: 'Concat'
    concat_param {
        axis: 1
    }
}

# Convolution+prod
layer { 
    name:  'preconv1' 
    top:  'preconv1' 
    bottom: 'packed_input'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 128
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'preconv1' 
    top:  'preconv1' 
    name:  'preconv1_relu' 
    type: 'ReLU'
}

layer {
    name: "preconv1_slice_"
    type: "Slice"
    bottom: "preconv1"
    
    top: "filters1"
    top: "masks1"

    slice_param {
        axis: 1
        slice_point: 64
    }
}

layer {
    name: "conv1"
    type: "Eltwise"
    bottom: "filters1"
    bottom: "masks1"
    top: "conv1"
    eltwise_param {
        operation: PROD
        stable_prod_grad:true
    }
} 

# Convolutions
layer { 
    name:  'conv2' 
    top:  'conv2' 
    bottom: 'conv1'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv2' 
    top:  'conv2' 
    name:  'conv2_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv3' 
    top:  'conv3' 
    bottom: 'conv2'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv3' 
    top:  'conv3' 
    name:  'conv3_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv4' 
    top:  'conv4' 
    bottom: 'conv3'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv4' 
    top:  'conv4' 
    name:  'conv4_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv5' 
    top:  'conv5' 
    bottom: 'conv4'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv5' 
    top:  'conv5' 
    name:  'conv5_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv6' 
    top:  'conv6' 
    bottom: 'conv5'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv6' 
    top:  'conv6' 
    name:  'conv6_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv7' 
    top:  'conv7' 
    bottom: 'conv6'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv7' 
    top:  'conv7' 
    name:  'conv7_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv8' 
    top:  'conv8' 
    bottom: 'conv7'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv8' 
    top:  'conv8' 
    name:  'conv8_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv9' 
    top:  'conv9' 
    bottom: 'conv8'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv9' 
    top:  'conv9' 
    name:  'conv9_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv10' 
    top:  'conv10' 
    bottom: 'conv9'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv10' 
    top:  'conv10' 
    name:  'conv10_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv11' 
    top:  'conv11' 
    bottom: 'conv10'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv11' 
    top:  'conv11' 
    name:  'conv11_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv12' 
    top:  'conv12' 
    bottom: 'conv11'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv12' 
    top:  'conv12' 
    name:  'conv12_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv13' 
    top:  'conv13' 
    bottom: 'conv12'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv13' 
    top:  'conv13' 
    name:  'conv13_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv14' 
    top:  'conv14' 
    bottom: 'conv13'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv14' 
    top:  'conv14' 
    name:  'conv14_relu' 
    type: 'ReLU'
}

layer { 
    name:  'conv15' 
    top:  'conv15' 
    bottom: 'conv14'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 128
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'conv15' 
    top:  'conv15' 
    name:  'conv15_relu' 
    type: 'ReLU'
}

# Product mask/filters
layer {
    name: "conv15_slice_"
    type: "Slice"
    bottom: "conv15"
    top: "filters"
    top: "masks"
    slice_param {
        axis: 1
        
        slice_point: 64
        
    }
}

layer {
    name: "filtered"
    type: "Eltwise"
    bottom: "filters"
    bottom: "masks"
    top: "filtered"
    eltwise_param {
        operation: PROD
        stable_prod_grad:true
    }
} 

layer { 
    name:  'residual' 
    top:  'residual' 
    bottom: 'filtered'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 12
        kernel_size: 1
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

# Unpack to final resolution
layer { 
    bottom: 'residual'
    top:  'residual_unpacked' 
    name: 'unpack_mosaick' 
    type: 'Deconvolution'
    param {lr_mult: 0 decay_mult: 0}
    convolution_param {  
        num_output: 3
        # bias_term: false
        group: 3
        kernel_size: 2
        stride:2
        weight_filler {
            type: "constant"
            value: 0
        }
    }
}

layer {
    name: "croppped_mosaick"
    type: "Python"
    bottom: "mosaick"
    bottom: "residual_unpacked"
    top: "cropped_mosaick"
    python_param {
        module: "demosaicnet.layers"
        layer: "CropLikeLayer"
    }
}



# Skip ahead
layer {
    name: 'packed'
    bottom: "cropped_mosaick"
    bottom: "residual_unpacked"
    top: 'packed'
    type: 'Concat'
    concat_param {
        axis: 1
    }
}

layer { 
    name:  'post_conv1' 
    top:  'post_conv1' 
    bottom: 'packed'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 64
        kernel_size: 3
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer { 
    bottom:  'post_conv1' 
    top:  'post_conv1' 
    name:  'post_conv1_relu' 
    type: 'ReLU'
}

layer { 
    name:  'output' 
    top:  'output' 
    bottom: 'post_conv1'
    type: 'Convolution'
    param {lr_mult: 1 decay_mult: 1}
    param {lr_mult: 2 decay_mult: 0}
    convolution_param {  
        num_output: 3
        kernel_size: 1
        pad: 0
        stride:1
        dilation: 1
        weight_filler {
            type: "msra"
            variance_norm: AVERAGE
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}
